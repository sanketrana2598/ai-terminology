<div align="center">
  <h3 align="center">AI Terminology Guide</h3>

  <p align="center">
    Prompt Engineering & Context Engineering
  </p>
</div>



This repository provides a streamlined AI terminology guide. It lists key terms and their common alternatives `without deep explanations` so you can quickly identify prevalent AI concepts. Use it to spot gaps in your knowledge and discover new terms to explore.


> ðŸ’¡ See ranking methodology, summary and learning path recommendations at the end of the document.

---

## FOUNDATION CONCEPTS

### Core Definitions

- **Prompt** <sup>[1/5]</sup> | `Natural language instruction, User query` - Natural language instruction or question given to an AI model
- **LLM** <sup>[2/5]</sup> | `Large Language Model, Generative language model, Neural language model` - AI model trained on massive text data to understand and generate human-like responses
- **Output** <sup>[1/5]</sup> | `Response, Generation, Completion` - Response generated by an AI model to a given prompt
- **Token** <sup>[2/5]</sup> | `Subword, Text unit` - Smallest unit of text (word, subword, or character) that an LLM processes
- **Prompt Engineering** <sup>[2/5]</sup> | `Prompt design, Instruction crafting` - Art of crafting effective instructions to guide AI models toward desired outputs
- **Context Engineering** <sup>[3/5]</sup> | `Knowledge management, Context design` - Designing and managing information systems provided to LLMs for reliable task completion

### Basic Interaction

- **Instruction Following** <sup>[1/5]</sup> | `Task execution, Directive understanding` - LLM's ability to understand and execute directions in natural language
- **Conversation History** <sup>[1/5]</sup> | `Message history, Context log, Dialogue record` - Record of previous messages exchanged with an LLM
- **Turn** <sup>[1/5]</sup> | `Exchange, Interaction cycle` - Single exchange in a multi-turn conversation between user and LLM
- **Response Generation** <sup>[2/5]</sup> | `Text generation, Output creation` - Process of LLM creating output based on input

## PROMPT ENGINEERING FUNDAMENTALS

### Prompting Techniques

- **Zero-Shot Prompting** <sup>[2/5]</sup> | `Direct prompting, No-example prompting` - Asking LLM to perform task without providing examples, relying entirely on pre-trained knowledge
- **One-Shot Prompting** <sup>[2/5]</sup> | `Single example prompting, Single demonstration` - Providing exactly one example to clarify the task for the model
- **Few-Shot Prompting** <sup>[2/5]</sup> | `In-context learning, Multi-shot learning, Demonstration-based prompting` - Providing a handful of examples (typically 2-5) to demonstrate desired pattern
- **In-Context Learning (ICL)** <sup>[3/5]</sup> | `Contextual learning, Learning from examples` - LLM's ability to learn from examples provided within prompt
- **System Prompt** <sup>[2/5]</sup> | `System message, Initial instruction` - Initial instructions defining LLM's behavior, role, and constraints
- **User Message** <sup>[1/5]</sup> | `User input, Query` - Instruction or query from end user
- **Developer Message** <sup>[2/5]</sup> | `Application-level instruction` - High-level instructions from application developer (takes priority)

### Prompt Optimization

- **Clarity** <sup>[1/5]</sup> | `Explicitness, Unambiguity` - Making instructions unambiguous and specific
- **Specificity** <sup>[1/5]</sup> | `Precision, Detail provision` - Providing exact details about desired output format, constraints, and requirements
- **Context Setting** <sup>[2/5]</sup> | `Background provision, Contextual framing` - Including relevant background information in prompt
- **Example Selection** <sup>[3/5]</sup> | `Demonstration curation, Example choice` - Choosing diverse, high-quality demonstrations for few-shot learning
- **Iterative Refinement** <sup>[2/5]</sup> | `Prompt iteration, Incremental improvement, Progressive refinement` - Continuously improving prompts based on results
- **Chain of Thought (CoT)** <sup>[3/5]</sup> | `Step-by-step reasoning, Sequential decomposition, Explicit reasoning` - Asking LLM to reason step-by-step through problem by articulating intermediate reasoning steps
- **Few-Shot Chain of Thought** <sup>[3/5]</sup> | `Demonstration-guided reasoning, CoT with examples` - Combining few-shot examples with step-by-step reasoning
- **Zero-Shot Chain of Thought** <sup>[3/5]</sup> | `Implicit reasoning, CoT without examples` - Using prompt cues like `let's think step by step" without examples
- **Emotion Prompting (EmotionPrompt)** <sup>[2/5]</sup> | `Psychological prompting, Motivational instructions` - Adding emotional/psychological stimuli ("This is critical," `Take a deep breath") shown to improve benchmark performance by 8%+

## ADVANCED PROMPT ENGINEERING

### Advanced Prompt Structures

- **Prompt Template** <sup>[3/5]</sup> | `Reusable structure, Prompt skeleton` - Reusable prompt structure with placeholders for variables
- **Prompt Caching** <sup>[4/5]</sup> | `Segment caching, Context reuse` - Storing frequently used prompt segments for efficiency
- **Prompt Versioning** <sup>[3/5]</sup> | `Version control, Iteration tracking` - Managing different iterations of prompts
- **Role-Playing** <sup>[2/5]</sup> | `Persona assignment, Character prompting, Role prompting` - Instructing LLM to assume specific persona or role for more context-specific, relevant responses
- **Identity Definition** <sup>[2/5]</sup> | `Behavior specification, Purpose definition` - Establishing LLM's purpose, communication style, and goals
- **Audience Calibration** <sup>[2/5]</sup> | `Audience Persona Pattern, Audience Persona` - Tailoring the language and detail of output to audience's knowledge level 
- **Prompt Patterns** <sup>[3/5]</sup> | `Reusable templates, Prompt recipes` - Cataloged, reusable prompt structures for specific tasks
- **Constraint Specification** <sup>[2/5]</sup> | `Boundary definition, Limitation setting` - Explicitly defining limits and requirements for outputs
- **Pseudo-Code Prompting** <sup>[3/5]</sup> | `Code-style instructions, Algorithmic prompting, Structured logic prompting` - Prompting using pseudo-code format with control flow syntax, providing structural clues through code comments and docstrings
- **XML/Markup Prompting** <sup>[3/5]</sup> | `Tag-based prompting, Hierarchical markup prompting` - Using XML-style tags to structure prompts and expected outputs, enabling grammar-constrained interaction with fixed-point semantics
- **JSON Prompting** <sup>[3/5]</sup> | `JSON-style prompts` - JSON-style prompts for structured data generation

### Output Control & Format

- **Output Format Specification** <sup>[2/5]</sup> | `Format definition, Structure specification` - Defining exact structure of desired response
- **Structured Output** <sup>[3/5]</sup> | `JSON generation, Schema-constrained output` - Constraining model to generate JSON or other structured data
- **JSON Schema** <sup>[3/5]</sup> | `Schema validation, Format enforcement` - Specifying exact JSON structure model must follow
- **Validation** <sup>[3/5]</sup> | `Output checking, Compliance verification` - Checking output meets business logic and schema requirements
- **Prefilling (Output Prefixing)** <sup>[2/5]</sup> | `Response priming, Output seeding, Partial completion` - Starting the assistant's response with the desired format or opening tokens to guide the model toward the expected structure (e.g., starting with `{` for JSON)
- **Grammar-Constrained Decoding (GCD)** <sup>[5/5]</sup> | `Grammar-guided generation, Formal grammar prompting, Syntax-constrained decoding` - Technique that restricts LLM token generation to only valid tokens according to a formal grammar (BNF, CFG), ensuring 100% syntactically correct outputs for domain-specific languages (SQL, JSON, PDDL, SMILES)

## ADVANCED REASONING STRATEGIES

### Reasoning Decomposition Techniques

- **Least-to-Most Prompting** <sup>[4/5]</sup> | `Progressive problem solving, Scaffolded reasoning` - Breaking complex problem into simpler subproblems by first breaking down then solving each sequentially, reformulating individual steps to restate previously concatenated results
- **Decomposed Prompting (DecomP)** <sup>[4/5]</sup> | `Task decomposition, Problem breakdown, Factored decomposition, Modular approach` - Breaking tasks into modular components and assigning them to appropriate handlers that can further decompose, solve with simple prompts, or use functions
- **Plan-and-Solve Prompting** <sup>[4/5]</sup> | `Planning-first reasoning, Two-phase reasoning` - Enhancing zero-shot CoT by introducing intermediate planning phase before problem-solving, addressing missing step errors by first planning approach then executing
- **Self-Consistency** <sup>[4/5]</sup> | `Multiple reasoning paths, Ensemble reasoning, Majority voting` - Sampling multiple reasoning paths and selecting most consistent answer through voting, improving reliability over single path reasoning
- **Analogical Reasoning** <sup>[3/5]</sup> | `Analogy-based prompting, Example-based inference` - Using analogies to guide LLM thinking by relating current problem to similar known scenarios
- **Tree of Thought (ToT)** <sup>[5/5]</sup> | `Branching reasoning, Path exploration` - Exploring multiple reasoning paths as tree structure where nodes represent partial solutions, allowing backtracking when paths are unlikely to succeed
- **Graph of Thought (GoT)** <sup>[5/5]</sup> | `Network reasoning, Interconnected logic` - Reasoning across interconnected knowledge as a graph where nodes can reference multiple prior nodes
- **Abstract Reasoning** <sup>[4/5]</sup> | `High-level thinking, Conceptual reasoning` - Working with high-level concepts rather than concrete details
- **Complexity-Based Prompting** <sup>[4/5]</sup> | `Adaptive depth, Problem-scaled reasoning` - Adjusting reasoning depth based on problem complexity, allocating more steps for harder problems
- **Comparative Reasoning** <sup>[3/5]</sup> | `Relational thinking, Comparison logic` - Understanding relationships between concepts through comparison
- **Skeleton-of-Thought (SoT)** <sup>[4/5]</sup> | `Outline-first generation, Hierarchical decomposition generation` - Two-stage approach: first generating skeleton outline, then expanding details in parallel, reducing latency for long-form outputs while maintaining structure
- **Chain of Density (CoD)** <sup>[3/5]</sup> | `Iterative densification, Entity-dense summarization` - Iteratively rewriting summaries to add missing salient entities while maintaining same length, increasing information density without increasing token count
- **Hint Chain Prompting (HoPC)** <sup>[4/5]</sup> | `Zero-shot pseudo code reasoning, Hint-guided decomposition` - Decomposing questions into sub-questions with general pseudo code hints as a chain, executed step-by-step as semantic code interpreter for clearer reasoning `mind map"
- **Step-Back Prompting** <sup>[4/5]</sup> | `Abstraction-first reasoning, Principle-based reasoning` - Evoking reasoning via abstraction by first taking a `step back" to identify high-level concepts and principles before solving the specific problem
- **Thread of Thought (ThoT)** <sup>[4/5]</sup> | `Sequential context processing, Iterative analysis` - Methodically processing, summarizing, and analyzing extended contexts in manageable parts by maintaining a `thread" of key information, resulting in more accurate responses for long documents
- **Recursion of Thought (RoT)** <sup>[5/5]</sup> | `Recursive decomposition, Divide-and-conquer reasoning` - Tackling context length limitations through recursive decomposition using divide-and-conquer approach, particularly effective for large-scale tasks and multi-digit arithmetic
- **Faithful Chain-of-Thought (CoT)** <sup>[5/5]</sup> | `Verifiable reasoning, Grounded step-by-step` - Ensuring LLM reasoning truly reflects the path to the answer, increasing trust and interpretability by guaranteeing final answers derive directly from the reasoning chain

### Self-Improvement Techniques

- **Self-Critique** <sup>[4/5]</sup> | `Self-evaluation, Output assessment` - LLM evaluating its own output for flaws
- **Self-Refine** <sup>[4/5]</sup> | `Iterative self-improvement, Self-correction, Feedback-driven refinement` - Iterative process of LLM improving its own output through multiple rounds
- **Self-Calibration** <sup>[4/5]</sup> | `Confidence assessment, Uncertainty estimation` - LLM assessing confidence in its responses and adjusting certainty levels
- **Self-Feedback** <sup>[4/5]</sup> | `Internal feedback, Self-assessment loop` - Using LLM's own evaluation to drive refinement
- **Iterative Refinement** <sup>[3/5]</sup> | `Multi-round improvement, Cyclic enhancement` - Multiple rounds of improvement with feedback loops
- **Reversing Chain-of-Thought (RCoT)** <sup>[5/5]</sup> | `Backward reasoning, Hallucination detection, Reverse verification` - Reconstructing problem from the answer backwards to detect hallucinations and verify reasoning consistency
- **Contrastive Chain of Thought (CCoT)** <sup>[4/5]</sup> | `Valid/invalid reasoning, Negative reasoning demonstration` - Generating both valid AND invalid reasoning paths (explaining why invalid one is wrong) before final answer, significantly reducing logical fallacies
- **Chain-of-Verification (CoVe)** <sup>[4/5]</sup> | `Verification questioning, Self-verification` - Having model generate verification questions to evaluate its initial response, then answering these questions to refine final output
- **Self-Verification** <sup>[3/5]</sup> | `Answer checking, Correctness validation` - Model verifies its own answers against constraints and requirements
- **Cumulative Reasoning** <sup>[4/5]</sup> | `Incremental knowledge building, Layered reasoning` - Building reasoning incrementally where each step adds to cumulative understanding

### Prompt Optimization Methods

- **Automatic Prompt Generation** <sup>[5/5]</sup> | `Automated prompt creation, Algorithm-based generation` - Using optimization algorithms to generate prompts
- **Automatic Prompt Optimization (APO)** <sup>[5/5]</sup> | `Self-optimizing prompts` - Refining prompts without manual intervention using gradient-based or search methods
- **MIPRO** <sup>[5/5]</sup> | `Multi-prompt Instruction Proposal Optimizer, Multi-stage optimization, Instruction tuning` - Optimizing multi-stage prompts
- **Meta-Prompting** <sup>[5/5]</sup> | `Prompt generation, Recursive prompting, Self-prompting` - Using LLMs to generate and optimize other prompts
- **AutoPrompt** <sup>[5/5]</sup> | `Automated trigger token discovery, Gradient-guided prompting` - Automatically discovering trigger tokens that elicit knowledge from language models using gradient-based search

## ADVANCED ZERO-SHOT TECHNIQUES

### Zero-Shot Enhancement Methods

- **Re-reading (RE2)** <sup>[3/5]</sup> | `Question re-examination, Deliberate re-reading` - Enhancing reasoning by explicitly asking model to re-read the prompt before answering, ensuring important details aren't missed and reducing comprehension errors
- **Rephrase and Respond (RaR)** <sup>[3/5]</sup> | `Question rephrasing, Clarity through reformulation` - Asking model to rephrase the prompt before answering, reducing ambiguity and improving clarity by letting model reformulate question in clearer terms
- **SimToM** <sup>[4/5]</sup> | `Simulated Theory of Mind, Perspective reasoning` - Enhancing LLMs' ability to understand and predict human thoughts and actions by simulating theory of mind reasoning

## CONTEXT ENGINEERING FOUNDATIONS

### Core Components

- **Knowledge Base** <sup>[2/5]</sup> | `Fact repository, Information repository` - Structured repository of domain-specific information
- **Context Window** <sup>[2/5]</sup> | `Token limit, Context length, Attention window` - Maximum amount of information/tokens LLM can consider at once
- **Working Memory** <sup>[2/5]</sup> | `Active context, Immediate memory` - Current context available to LLM during generation
- **Persistent Memory** <sup>[4/5]</sup> | `External memory, Long-term storage, Knowledge storage` - External storage (vector database, knowledge base) outside context window

### Information Processing

- **Information Retrieval** <sup>[3/5]</sup> | `Data extraction, Document retrieval` - Extracting relevant data from external sources
- **Context Retrieval** <sup>[3/5]</sup> | `Information sourcing, Document fetching` - Actively sourcing relevant data from external sources
- **Context Processing** <sup>[4/5]</sup> | `Information optimization, Signal refinement` - Optimizing raw information for maximum signal-to-noise
- **Chunking** <sup>[3/5]</sup> | `Text segmentation, Document splitting` - Breaking large documents into smaller, manageable pieces
- **Summarization** <sup>[3/5]</sup> | `Content condensing, Key point extraction` - Condensing information while preserving key meaning
- **Compression** <sup>[4/5]</sup> | `Context reduction, Token minimization` - Reducing context size while maintaining relevant information
- **Context Management** <sup>[4/5]</sup> | `Context orchestration, Information selection` - Orchestrating what information enters LLM's context window
- **System 2 Attention (S2A)** <sup>[5/5]</sup> | `Context denoising, Deliberate attention prompting` - Asking LLM to regenerate input context removing irrelevant information and bias before answering, addressing the `lost in the middle" phenomenon and sycophancy issues

### Memory Architectures

- **Episodic Memory** <sup>[3/5]</sup> | `Event memory, Interaction history` - Storing specific events or interactions
- **Semantic Memory** <sup>[3/5]</sup> | `Fact memory, Knowledge storage` - Long-term storage of facts and knowledge
- **Memory Mechanisms** <sup>[4/5]</sup> | `Memory systems, Retrieval mechanisms` - Systems for storing and retrieving information
- **State Persistence** <sup>[4/5]</sup> | `Information continuity, Session memory` - Maintaining information across multiple interactions

## RETRIEVAL & AUGMENTATION SYSTEMS

### Retrieval Methods

- **Retrieval-Augmented Generation (RAG)** <sup>[4/5]</sup> | `Knowledge-augmented generation, Context-injection generation` - Retrieving relevant external documents before generation
- **Dense Retrieval** <sup>[4/5]</sup> | `Neural embedding search, Semantic retrieval` - Using neural embeddings for semantic similarity search
- **Sparse Retrieval** <sup>[3/5]</sup> | `Keyword search, Lexical retrieval, BM25 search` - Traditional keyword-based search methods
- **Hybrid Retrieval** <sup>[5/5]</sup> | `Combined search, Semantic-keyword fusion` - Combining dense and sparse retrieval methods
- **Vector Search** <sup>[4/5]</sup> | `Similarity search, Embedding-based search` - Searching based on numerical vector representations
- **Semantic Search** <sup>[4/5]</sup> | `Meaning-based search, Context-aware retrieval` - Finding information based on meaning rather than exact keywords
- **Cascading Retrieval** <sup>[5/5]</sup> | `Sequential search, Multi-stage retrieval` - Sequential application of multiple retrieval methods

### Advanced Retrieval Architectures

- **BM25** <sup>[3/5]</sup> | `Probabilistic ranking, TF-IDF variant` - Probabilistic retrieval model for keyword-based ranking
- **Dense vs Sparse Tradeoff** <sup>[4/5]</sup> | `Semantic-keyword balance, Precision-recall tradeoff` - Balancing semantic understanding with exact matching
- **Ranking Fusion** <sup>[4/5]</sup> | `Score combination, Multi-signal ranking` - Combining multiple ranking signals
- **Reciprocal Rank Fusion (RRF)** <sup>[4/5]</sup> | `Harmonic mean ranking, Normalized scoring` - Technique for merging ranked retrieval results
- **Learning-to-Rank (LTR)** <sup>[5/5]</sup> | `Gradient boosting ranking` - Machine learning approach to optimize ranking
- **Reranking** <sup>[4/5]</sup> | `Result reordering, Relevance ranking` - Re-ordering retrieved results by relevance
- **Cross-Encoder** <sup>[5/5]</sup> | `Pair-wise scoring, Document-query ranking` - Neural model that scores document-query pairs
- **Late Interaction** <sup>[5/5]</sup> | `Refinement matching, Secondary ranking` - Refined matching using multiple signals

## ADVANCED CONTEXT ENGINEERING

### Knowledge Representation

- **Knowledge Graph (KG)** <sup>[4/5]</sup> | `Entity-relation graph, Semantic network` - Structured representation of entities and relationships
- **Entity Linking** <sup>[4/5]</sup> | `Reference resolution, Entity mapping` - Connecting text mentions to knowledge base entities
- **Graph-Based Retrieval** <sup>[5/5]</sup> | `Graph traversal, Relational search` - Using knowledge graphs for information retrieval
- **Knowledge Graph Embedding** <sup>[5/5]</sup> | `Graph vectorization, KG representation` - Vectorizing knowledge graphs for search

### Vector & Semantic Systems

- **Vector Embedding** <sup>[3/5]</sup> | `Numerical representation, Semantic vector` - Numerical representation capturing semantic meaning
- **Embedding Model** <sup>[4/5]</sup> | `Encoder model, Text-to-vector converter` - Neural model converting text to vector representations
- **Vector Database** <sup>[4/5]</sup> | `Embedding storage, Vector index` - Storage system optimized for vector similarity search
- **Semantic Similarity** <sup>[3/5]</sup> | `Meaning similarity, Contextual closeness` - Measuring meaning similarity between texts
- **Vector Space** <sup>[3/5]</sup> | `Embedding space, Semantic space` - Mathematical space where embeddings reside

### System Integration

- **Model Context Protocol (MCP)** <sup>[5/5]</sup> | `Context protocol, Standardized interface` - Standard protocol for exposing context to LLMs
- **MCP Servers** <sup>[5/5]</sup> | `Context providers, Protocol servers` - Services exposing structured context through MCP
- **MCP Clients** <sup>[4/5]</sup> | `Protocol consumers, Application clients` - Applications initiating MCP requests
- **Agent Architecture** <sup>[5/5]</sup> | `Multi-component system, Decision framework` - Multi-component system with decision-making capabilities

## FOUNDATIONAL MODEL THEORY & ARCHITECTURE

### Model Architecture & Mechanisms

- **Transformer Architecture** <sup>[5/5]</sup> | `Self-attention networks, Modern neural design` - Neural network design underlying modern LLMs
- **Attention Mechanism** <sup>[4/5]</sup> | `Focus mechanism, Selective weighting` - Focusing on relevant parts of input
- **Self-Attention** <sup>[5/5]</sup> | `Intra-attention, Internal relationships` - Mechanism for relating different positions within a sequence
- **Cross-Attention** <sup>[5/5]</sup> | `External focus` - Attention mechanism between different input sequences

### Probability & Normalization

- **Softmax Function** <sup>[4/5]</sup> | `Probability converter, Normalization function` - Mathematical function converting scores to probabilities
- **Probability Distribution** <sup>[4/5]</sup> | `Likelihood representation, Statistical distribution` - Mathematical representation of likelihood
- **Logits** <sup>[3/5]</sup> | `Raw scores, Pre-normalization values` - Raw prediction scores before probability conversion
- **Semantic Relationships** <sup>[3/5]</sup> | `Meaning connections, Semantic links` - Meaning connections between concepts

### Decoding & Generation

- **Inference** <sup>[3/5]</sup> | `Model execution, Prediction generation` - Running LLM to generate output
- **Decoding** <sup>[3/5]</sup> | `Output conversion, Text generation` - Converting model outputs into human-readable text
- **Stochastic Behavior** <sup>[4/5]</sup> | `Random behavior, Probabilistic output` - Non-deterministic output generation
- **Probability Sampling** <sup>[3/5]</sup> | `Likelihood-based selection, Random drawing` - Selecting options based on likelihood
- **Speculative Decoding** <sup>[5/5]</sup> | `Draft-verify generation, Assisted decoding, Parallel token verification` - Inference optimization using small draft model to propose multiple tokens, verified in parallel by target model, achieving 2-3x â€” speedup with no quality loss

---

## MODEL PARAMETERS & CONFIGURATION

### Sampling & Randomness

- **Temperature** <sup>[2/5]</sup> | `Randomness control, Creativity parameter` - Controls randomness/creativity of output (0=deterministic, high=creative)
- **Top-K Sampling** <sup>[3/5]</sup> | `K-truncation, Token filtering` - Selecting next token from K most probable options
- **Top-P (Nucleus Sampling)** <sup>[3/5]</sup> | `Probability threshold, Cumulative sampling` - Selecting from tokens with cumulative probability up to P
- **Greedy Decoding** <sup>[2/5]</sup> | `Maximum likelihood, Deterministic selection` - Always selecting highest probability token (deterministic)
- **Random Sampling** <sup>[2/5]</sup> | `Stochastic selection, Uniform sampling` - Randomly selecting from entire token distribution

### Generation Controls

- **Max Tokens** <sup>[1/5]</sup> | `Length limit, Output cap` - Maximum length of generated response
- **Frequency Penalty** <sup>[2/5]</sup> | `Repetition penalty, Word reuse reduction` - Reducing likelihood of repeating same words
- **Presence Penalty** <sup>[2/5]</sup> | `Topic diversity, New content encouragement` - Encouraging introduction of new topics
- **Sampling Parameters** <sup>[3/5]</sup> | `Generation settings, Output controls` - Controls affecting token selection during generation

### Model Selection & Tuning

- **Model Snapshots** <sup>[2/5]</sup> | `Version pinning, Model versioning` - Specific versions of models pinned for consistency
- **Fine-Tuning** <sup>[4/5]</sup> | `Parameter adjustment, Model training` - Adjusting model parameters on specific data
- **Prompt Tuning** <sup>[4/5]</sup> | `Soft prompting, Token learning` - Learning soft tokens to prepend to prompts
- **Prefix Tuning** <sup>[5/5]</sup> | `Prompt prefix learning, Adapter-based tuning` - Learning parameters at each layer of model
- **LoRA** <sup>[5/5]</sup> | `Low-Rank Adaptation, Parameter-efficient fine-tuning` - Fine-tuning only low-rank decomposition matrices of weight layers
- **QLoRA** <sup>[5/5]</sup> | `Quantized Low-Rank Adaptation` - Combining quantization with LoRA for memory-efficient fine-tuning
- **PEFT** <sup>[5/5]</sup> | `Parameter-Efficient Fine-Tuning, Adapter methods` - Techniques for fine-tuning with minimal trainable parameters
- **Quantization** <sup>[4/5]</sup> | `Model compression, Bit reduction` - Reducing model precision (Int8, FP16, 4-bit) to decrease size and increase speed
- **Int8 Quantization** <sup>[4/5]</sup> | `8-bit integer quantization` - Converting model weights to 8-bit integers
- **4-bit Quantization** <sup>[5/5]</sup> | `Extreme quantization, Ultra-lightweight models` - Converting model weights to 4-bit integers for minimal memory footprint
- **GGUF Format** <sup>[4/5]</sup> | `GPT-Generated Unified Format` - Portable format for quantized models enabling local inference
- **GPTQ Format** <sup>[5/5]</sup> | `Quantization method for GPU inference` - Quantization technique optimized for GPU hardware
- **AWQ Format** <sup>[5/5]</sup> | `Activation-Aware Quantization` - Advanced quantization preserving most important weights
- **Reasoning Models** <sup>[4/5]</sup> | `Deliberative models, Step-by-step thinkers` - Models trained for explicit step-by-step reasoning

## ADVANCED INTERACTION PATTERNS

### Multi-Agent Systems

- **Multi-Agent Systems** <sup>[5/5]</sup> | `Agent teams, Collaborative agents` - Multiple specialized LLMs working collaboratively
- **Agent Orchestration** <sup>[5/5]</sup> | `Agent coordination, Task delegation` - Coordinating agents to accomplish complex tasks
- **Intent Translation** <sup>[4/5]</sup> | `Request conversion, Goal interpretation` - Converting user requests into actionable instructions
- **Agentic Reasoning** <sup>[5/5]</sup> | `Agent decision-making, Autonomous planning` - LLM deciding which steps to take to solve problem
- **Plan Decomposition** <sup>[4/5]</sup> | `Task breakdown, Subtask creation` - Breaking user request into sub-tasks
- **Stateful Agents** <sup>[5/5]</sup> | `Persistent agents, Memory-retaining systems` - Agents maintaining persistent state across sessions
- **Multi-Step Planning** <sup>[5/5]</sup> | `Sequential planning, Dependency management` - Complex task sequences with dependencies
- **Cross-Domain Orchestration** <sup>[5/5]</sup> | `Multi-system coordination, Federated agents` - Coordinating multiple specialized systems
- **Autonomous Systems** <sup>[5/5]</sup> | `Self-directed systems, Unsupervised agents` - LLM-based systems operating without human intervention
- **Collaborative AI** <sup>[5/5]</sup> | `Cooperative systems, Inter-AI collaboration` - Multiple AI systems working together
- **ReAct (Reason + Act)** <sup>[5/5]</sup> | `Interleaved reasoning and acting, Thought-Action-Observation` - Prompting paradigm alternating Thought (reasoning), Action (tool call), and Observation (result) steps in a loop for agentic tasks - industry-standard pattern for tool-using agents
- **Multi-Persona Self-Collaboration (Solo Performance Prompting)** <sup>[5/5]</sup> | `Multiple perspectives, Role diversity` - LLM collaborates with itself by adopting multiple personas to tackle complex tasks through diverse viewpoints

### Function Calling & Tool Use

- **Function Calling** <sup>[4/5]</sup> | `API invocation, Tool calling` - Instructing LLM to call external functions with arguments
- **Tool Use** <sup>[4/5]</sup> | `External API usage, Capability extension` - LLM invoking external APIs and services
- **Tool Definition** <sup>[3/5]</sup> | `Function specification, Capability definition` - Specifying available functions and their parameters
- **Agentic Workflows** <sup>[5/5]</sup> | `Agent-driven processes, Autonomous task execution` - Multi-step processes where LLM decides which tools to use
- **Tool Chaining** <sup>[5/5]</sup> | `Function sequencing, Workflow composition` - Sequencing multiple tool calls to accomplish complex tasks
- **Program-Aided Language Models (PAL)** <sup>[5/5]</sup> | `Code-driven reasoning, Programmatic problem-solving` - Separating reasoning from computation by expressing reasoning as executable code (Python) that is sent to programmatic runtime, particularly valuable for complex calculations and iterative processes
- **Chain-of-Code (CoC)** <sup>[5/5]</sup> | `Code-language hybrid reasoning, Semantic-numeric bridge` - Framework combining precision of code execution with flexibility of language-based reasoning by generating and executing mix of code and natural language

### Processing Patterns

- **Streaming** <sup>[3/5]</sup> | `Token streaming, Real-time generation` - Processing response tokens as they're generated
- **Batch Processing** <sup>[3/5]</sup> | `Bulk requests, Grouped processing` - Handling multiple requests in single API call
- **Chunked Processing** <sup>[3/5]</sup> | `Segmented handling, Partial processing` - Breaking responses into manageable pieces

### Context Optimization

- **Token Budgeting** <sup>[4/5]</sup> | `Token allocation, Context distribution` - Managing token allocation across context elements
- **Provenance Tracking** <sup>[4/5]</sup> | `Source logging, Information tracing` - Logging which information was provided to LLM
- **Scratchpad** <sup>[4/5]</sup> | `Work memory, Intermediate storage` - External memory for agents to record intermediate work
- **Thought Chains** <sup>[4/5]</sup> | `Reasoning trace, Explanation chain` - Visible reasoning steps leading to conclusions
- **Tool-Augmented Generation** <sup>[5/5]</sup> | `Tool-enhanced output, Capability extension` - Using external tools during generation

## CODE GENERATION & COMPLETION

### Code-Specific Techniques

- **Fill-in-the-Middle (FIM)** <sup>[4/5]</sup> | `Infilling, Middle completion, Context-aware insertion` - Technique where model generates missing code/text given both prefix and suffix context, using special sentinel tokens (PSM, SPM, or AST-aware formats)
- **Horizon-Length Prediction (HLP)** <sup>[5/5]</sup> | `Lookahead planning for FIM, Adaptive infilling` - Advanced FIM variant where model predicts normalized length of missing middle content before generation, improving boundary detection by 24%


## METRICS & EVALUATION

### Quality Metrics

- **Perplexity** <sup>[3/5]</sup> | `Model uncertainty, Prediction entropy` - Measure of how uncertain a language model is about predictions (lower is better)
- **BLEU** <sup>[3/5]</sup> | `Bilingual Evaluation Understudy` - Precision-based metric comparing machine translation to reference translations
- **ROUGE** <sup>[3/5]</sup> | `Recall-Oriented Understudy for Gisting Evaluation` - Set of metrics measuring summary quality via n-gram overlap
- **METEOR** <sup>[4/5]</sup> | `Metric for Evaluation of Translation with Explicit Ordering` - Translation metric accounting for synonymy and paraphrases
- **RAGAS Score** <sup>[5/5]</sup> | `Retrieval-Augmented Generation Assessment, Automated evaluation` - Automated RAG pipeline evaluation measuring retrieval and generation quality

### RAG-Specific Metrics

- **Faithfulness** <sup>[5/5]</sup> | `Hallucination prevention, Grounding score` - Measure of whether generated answer is faithful to retrieved context
- **Answer Relevance** <sup>[4/5]</sup> | `Response pertinence, Query-answer alignment` - Measure of how relevant generated answer is to user query
- **Context Recall** <sup>[5/5]</sup> | `Retrieval completeness, Information recall` - Measure of retrieval system's ability to return all relevant documents
- **Context Precision** <sup>[5/5]</sup> | `Signal-to-noise ratio, Relevant content density` - Measure of proportion of retrieved documents that contain relevant information

### Evaluation & Testing

- **Prompt Evaluation** <sup>[3/5]</sup> | `Performance testing, Quality assessment` - Testing prompt effectiveness across tasks
- **Evals** <sup>[3/5]</sup> | `Automated testing, Benchmark tests` - Automated tests ensuring consistent behavior
- **Observability** <sup>[4/5]</sup> | `Monitoring, Logging` - Logging and monitoring LLM behavior

## RELIABILITY, SAFETY & SECURITY

### Hallucination & Grounding

- **Hallucination** <sup>[2/5]</sup> | `Fabrication, False generation` - LLM generating false information confidently
- **Hallucination Mitigation** <sup>[4/5]</sup> | `Falsification prevention, Grounding techniques` - Techniques reducing false outputs
- **Grounding** <sup>[4/5]</sup> | `Fact anchoring, Source verification` - Anchoring LLM outputs in verified sources
- **Factual Accuracy** <sup>[3/5]</sup> | `Truth verification, Reality alignment` - Ensuring outputs match reality

### Error Handling & Safety

- **Safety Alignment** <sup>[5/5]</sup> | `Value alignment, Ethical constraints` - Ensuring outputs follow ethical guidelines
- **Bias Mitigation** <sup>[4/5]</sup> | `Bias reduction, Fairness improvement` - Reducing prejudiced outputs

### Security & Adversarial

- **Prompt Injection** <sup>[4/5]</sup> | `Adversarial prompting, Prompt hacking` - Manipulating prompts to influence outputs adversarially
- **Jailbreaking** <sup>[4/5]</sup> | `Constraint bypass, Safeguard circumvention` - Attempts to bypass LLM safety constraints or guidelines
- **Prompt Leaking** <sup>[3/5]</sup> | `System prompt extraction, Information disclosure` - Form of prompt injection where model is asked to output its own prompt, exposing hidden instructions and intellectual property
- **Data Poisoning** <sup>[5/5]</sup> | `Training data manipulation, Model contamination` - Intentionally corrupting training data to degrade model
- **Model Collapse** <sup>[5/5]</sup> | `Recursive training degradation, Quality decline` - Performance degradation from repeated training on model-generated data
- **Indirect Prompt Injection** <sup>[5/5]</sup> | `Data-based attack, Second-order injection` - Injecting prompts through data (documents, web pages) retrieved by system
- **Refusal Suppression** <sup>[4/5]</sup> | `Safety constraint elimination, Refusal blocking` - Sophisticated jailbreak that explicitly constrains model's ability to refuse unsafe requests by prohibiting apologetic language, disclaimers, and refusal words
- **Obfuscation** <sup>[3/5]</sup> | `Content filter evasion, Text transformation` - Technique evading content filters by modifying restricted words through encoding, typos, character substitution, or phonetic preservation
- **Token Smuggling** <sup>[4/5]</sup> | `Encoded payload delivery, Hidden instruction embedding` - Embedding malicious instructions in encoded or obfuscated form to bypass safety filters
- **Special Case Attack** <sup>[4/5]</sup> | `Edge case exploitation, Boundary condition attack` - Exploiting specific edge cases or boundary conditions where safety mechanisms are weaker

### Defensive Measures

- **Separate LLM Evaluation** <sup>[4/5]</sup> | `Security layer, Input analysis` - Using separate LLM to analyze user inputs for potential risks before main model processes them, adding extra security layer

## ECOSYSTEM & FRAMEWORKS

### Popular AI Frameworks & Tools

- **LangChain** <sup>[4/5]</sup> | `LLM orchestration framework, Chain composition` - Framework for building applications with language models through chaining patterns
- **LlamaIndex** <sup>[4/5]</sup> | `Data framework, RAG indexing` - Framework for indexing and retrieving data for RAG systems
- **Ollama** <sup>[3/5]</sup> | `Local inference engine, Model runner` - Tool for running large language models locally
- **vLLM** <sup>[5/5]</sup> | `Inference optimization, High-throughput serving` - Inference engine optimized for high-throughput LLM serving
- **OpenAI Assistants API** <sup>[4/5]</sup> | `Stateful threads, Assistant management` - API providing persistent threads and assistant state management
- **DSPy** <sup>[5/5]</sup> | `Declarative programming, Modular prompting` - Framework for declarative optimization of language models

## RESEARCH FRONTIERS & EMERGING CONCEPTS

### Advanced Reasoning Systems

- **Constitutional AI** <sup>[5/5]</sup> | `Principle-based AI, Value-driven systems` - LLMs following explicit constitution of principles
- **Value Learning** <sup>[5/5]</sup> | `Human value alignment, Ethics learning` - Models learning human values from examples
- **Interpretability** <sup>[5/5]</sup> | `Model transparency, Explainability` - Understanding LLM decision-making processes
- **Mechanistic Interpretability** <sup>[5/5]</sup> | `Internal mechanics, Circuit understanding` - Understanding internal computations
- **Emergent Capabilities** <sup>[5/5]</sup> | `Spontaneous abilities, Scale-dependent features` - Abilities appearing unexpectedly at scale

### Frontier Techniques

- **Adaptive Prompting** <sup>[5/5]</sup> | `Dynamic prompts, Context-sensitive adaptation` - Dynamically adjusting prompts based on context
- **Dynamic Retrieval** <sup>[5/5]</sup> | `On-the-fly retrieval, Conditional fetching` - Changing what information to retrieve mid-task
- **Continuous Learning** <sup>[5/5]</sup> | `Incremental learning, Ongoing improvement` - Systems that improve through interaction
- **Multimodal Context** <sup>[5/5]</sup> | `Mixed media, Multi-sensory input` - Integrating text, images, audio in context
- **Neuromorphic Architectures** <sup>[5/5]</sup> | `Brain-inspired AI, Biologically-motivated systems` - Brain-inspired system designs

### Knowledge Enhancement

- **Generated Knowledge Prompting** <sup>[4/5]</sup> | `Knowledge generation, Pre-answer knowledge` - Asking LLM to generate relevant knowledge before answering the actual question to improve reasoning
- **Knowledge Augmentation** <sup>[4/5]</sup> | `External knowledge, Information enrichment` - Adding external knowledge to improve reasoning
- **Knowledge Integration** <sup>[5/5]</sup> | `Multi-source synthesis, Knowledge fusion` - Combining multiple knowledge sources
- **Contextual Knowledge** <sup>[3/5]</sup> | `Context-specific facts, Relevant knowledge` - Domain-specific information for tasks
- **Cross-Domain Knowledge** <sup>[4/5]</sup> | `Transfer learning, Multi-domain insight` - Applying knowledge across different fields

## NOTES

### Legend

| Symbol | Meaning | Description |
|--------|---------|-------------|
| <sup>[5/5]</sup> | Expert/Research | Cutting-edge AI techniques requiring deep expertise |
| <sup>[4/5]</sup> | Advanced | Complex AI concepts for experienced practitioners |
| <sup>[3/5]</sup> | Intermediate | Core AI techniques requiring solid understanding |
| <sup>[2/5]</sup> | Beginner | Foundational AI concepts all users should know |
| <sup>[1/5]</sup> | Essential | Must-know basics for any AI/LLM interaction |

### Ranking Methodology

Terms are ranked based on:
- **Conceptual Complexity**: Mathematical/theoretical depth required
- **Implementation Difficulty**: Technical skill needed to apply
- **Prerequisites**: Required foundational AI knowledge
- **Research Maturity**: Established vs emerging AI techniques

### Learning Path Recommendations

**Beginner Journey:**
1. Foundation Concepts & Basic Interaction
2. Basic Prompting Techniques (Zero-shot, One-shot, Few-shot)
3. Simple Parameter Controls (Temperature, Max Tokens)
4. Understanding Output and Tokens
5. Emotion Prompting for performance gains
6. Role-Playing for context-specific responses

**Intermediate Journey:**
1. Advanced Prompting (Chain of Thought, Role-Playing)
2. Context Engineering Foundations
3. Basic RAG Concepts
4. Prompt Templates and Patterns
5. Pseudo-Code Prompting
6. Chain of Density for summarization
7. Re-reading and Rephrase-and-Respond techniques

**Advanced Journey:**
1. Complex Reasoning Strategies (Self-Consistency, Tree of Thought)
2. RAG System Architecture
3. Vector Databases and Embeddings
4. Multi-Agent Coordination
5. Fine-Tuning and Quantization
6. Skeleton-of-Thought for latency
7. System 2 Attention for context optimization
8. Fill-in-the-Middle for code generation
9. Step-Back Prompting and Thread of Thought
10. Chain-of-Verification and Self-Criticism

**Expert/Research Journey:**
1. Cutting-Edge Reasoning (Graph of Thought, Meta-Prompting)
2. Advanced RAG Architectures (Hybrid Retrieval, Cross-Encoders)
3. Model Architecture Theory (Transformers, Self-Attention)
4. AI Security Research (Advanced Attacks, Safety Alignment)
5. Frontier AI Techniques (Neuromorphic, Constitutional AI)
6. Grammar-Constrained Decoding for perfect syntax
7. ReAct pattern for autonomous agents
8. Speculative Decoding for 2-3xâ€” speedup
9. Horizon-Length Prediction for advanced code generation
10. Recursion of Thought for large-scale tasks
11. PAL and Chain-of-Code for programmatic reasoning

**Specialist Path (Prompt Security):**
1. Start: Prompt Injection Jailbreaking
2. Progress: Prompt Leaking Refusal Suppression
3. Advanced: Obfuscation Token Smuggling
4. Defense: Separate LLM Evaluation Safety Alignment

**Specialist Path (Structured Output Engineering):**
1. Start: JSON Schema Structured Output
2. Progress: Prefilling Pseudo-Code Prompting
3. Advanced: XML/Markup Prompting Grammar-Constrained Decoding
4. Master: Integration with validation and error handling

**Specialist Path (RAG/Retrieval Systems):**
1. Start: Vector Embeddings Vector Databases
2. Progress: Dense Retrieval Hybrid Methods
3. Advanced: RAG-Specific Metrics Cross-Encoders
4. Optimization: System 2 Attention Context Window Management

## LICENSE

MIT License
This AI terminology guide is released under the MIT License. You are free to use, modify, and distribute this guide for personal and commercial purposes, with attribution.

## CONTRIBUTING

Contributions are welcome! If you have suggestions for new AI terminology, improvements to definitions, or corrections. 
Just submit a pull request!